{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate='''timestamp    datetime of record in yyyy-mm-dd hh:mm:ss format    datetime\n",
    "PPO:AC4_1A:TIC7201-PV    Autoclave 4 Compartment 1A Temperature (°C)    Float\n",
    "PPO:AC4_1B:TIC7202-PV    Autoclave 4 Compartment 1B Temperature (°C)    Float\n",
    "PPO:AC4_1C:TIC7203-PV    Autoclave 4 Compartment 1C Temperature (°C)    Float\n",
    "PPO:AC4_2:TIC7204-PV    Autoclave 4 Compartment 2 Temperature (°C)    Float\n",
    "PPO:AC4_3:TIC7205-PV    Autoclave 4 Compartment 3 Temperature (°C)    Float\n",
    "PPO:AC4_4:TIC7206-PV    Autoclave 4 Compartment 4 Temperature (°C)    Float\n",
    "PPO:AC4_5:TIC7207-PV    Autoclave 4 Compartment 5 Temperature (°C)    Float\n",
    "PPO:AC4_6:TIC7208-PV    Autoclave 4 Compartment 6 Temperature (°C)    Float\n",
    "PPO:AC2004:AVEG-TEMP    Autoclave 4 Average of Selected Temperature (°C)    Float\n",
    "PPO:AC4_1A:FIC7201-PV    Autoclave 4 Compartment 1A O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_1A:FIC7271-PV    Autoclave 4 Compartment 1A Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_1B:FIC7202-PV    Autoclave 4 Compartment 1B O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_1B:FIC7272-PV    Autoclave 4 Compartment 1B Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_1C:FIC7203-PV    Autoclave 4 Compartment 1C O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_1C:FIC7273-PV    Autoclave 4 Compartment 1C Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_2:FIC7204-PV    Autoclave 4 Compartment 2 O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_2:FIC7274-PV    Autoclave 4 Compartment 2 Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_3:FIC7205-PV    Autoclave 4 Compartment 3 O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_3:FIC7275-PV    Autoclave 4 Compartment 3 Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_4:FIC7206-PV    Autoclave 4 Compartment 4 O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_4:FIC7276-PV    Autoclave 4 Compartment 4 Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_5:FIC7207-PV    Autoclave 4 Compartment 5 O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_5:FIC7277-PV    Autoclave 4 Compartment 5 Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_6:FIC7208-PV    Autoclave 4 Compartment 6 O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_6:FIC7278-PV    Autoclave 4 Compartment 6 Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_1A:WIC7211-PV    Autoclave 4 Compartment 1A Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_1B:WIC7212-PV    Autoclave 4 Compartment 1B Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_1C:WIC7213-PV    Autoclave 4 Compartment 1C Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_2:WIC7214-PV    Autoclave 4 Compartment 2 Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_3:WIC7215-PV    Autoclave 4 Compartment 3 Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_4:WIC7216-PV    Autoclave 4 Compartment 4 Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_5:WIC7217-PV    Autoclave 4 Compartment 5 Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_6:WIC7218-PV    Autoclave 4 Compartment 6 Oxygen Mass Flow (t/h)    Float\n",
    "PPO:PU2033:FI7061    Autoclave 4 Feed Pump PU2033 Volume Flow (m3/h)    Float\n",
    "PPO:PU2034:FI7062    Autoclave 4 Feed Pump PU2034 Volume Flow (m3/h)    Float\n",
    "PPO:PU2035:FI7063    Autoclave 4 Feed Pump PU2035 Volume Flow (m3/h)    Float\n",
    "PPO:PU2033:WI7061    Autoclave 4 Feed Pump PU2033 Mass Flow (t/h)    Float\n",
    "PPO:PU2034:WI7062    Autoclave 4 Feed Pump PU2034 Mass Flow (t/h)    Float\n",
    "PPO:PU2035:WI7063    Autoclave 4 Feed Pump PU2035 Mass Flow (t/h)    Float\n",
    "PPO:PU2033:WIC7064-PV    Autoclave 4 Total Mass Flow (t/h)    Float\n",
    "PPO:PU2741:TIC7182-PV    Autoclave 4 Feed Slurry Temperature (°C)    Float\n",
    "PPO:L-AC4 FD_S2_2HR_SQL    Autoclave 4 Feed Sulphide Sulphur 3 Hourly Sample (Mass %)    Float\n",
    "PPO:L-AC4FD_RS_2HR_SQL    Autoclave 4 Feed Reactive Sulphur 3 Hourly Sample (Mass %)    Float\n",
    "PPO:L-AC4 FD_CACO3_2HR_SQL    Autoclave 4 Feed Calcium Carbonate 3 Hourly Sample (Mass %)    Float\n",
    "PPO:L-AC4 FD_PH_2HR_SQL    Autoclave 4 Feed pH 3 Hourly Sample (pH)    Float\n",
    "PPO:AG2241:JIC7201-PV    Autoclave 4 Compartment 1A Agitator Power (kWhr)    Float\n",
    "PPO:AG2242:JIC7202-PV    Autoclave 4 Compartment 1B Agitator Power (kWhr)    Float\n",
    "PPO:AG2243:JIC7203-PV    Autoclave 4 Compartment 1C Agitator Power (kWhr)    Float\n",
    "PPO:AG2244:JIC7204-PV    Autoclave 4 Compartment 2 Agitator Power (kWhr)    Float\n",
    "PPO:AG2245:JIC7205-PV    Autoclave 4 Compartment 3 Agitator Power (kWhr)    Float\n",
    "PPO:AG2246_PWR    Autoclave 4 Compartment 4 Agitator Power (kWhr)    Float\n",
    "PPO:AG2247_PWR    Autoclave 4 Compartment 5 Agitator Power (kWhr)    Float\n",
    "PPO:AG2248_PWR    Autoclave 4 Compartment 6 Agitator Power (kWhr)    Float\n",
    "PPO:AG2241:AG2241-RPM    Autoclave 4 Compartment 1A Agitator Speed (rpm)    Float\n",
    "PPO:AG2242:AG2242-RPM    Autoclave 4 Compartment 1B Agitator Speed (rpm)    Float\n",
    "PPO:AG2243:AG2243-RPM    Autoclave 4 Compartment 1C Agitator Speed (rpm)    Float\n",
    "PPO:AG2244:AG2244-RPM    Autoclave 4 Compartment 2 Agitator Speed (rpm)    Float\n",
    "PPO:AG2245:AG2245-RPM    Autoclave 4 Compartment 3 Agitator Speed (rpm)    Float\n",
    "PPO:AC2004:PIC7065A-PV    Autoclave 4 Pressure (kPa)    Float\n",
    "PPO:PV2016:PV7127    Autoclave 4 Train 1 Pressure Control Valve Open Position (%)    Float\n",
    "PPO:PV2017:PV7137    Autoclave 4 Train 2 Pressure Control Valve Open Position (%)    Float\n",
    "PPO:AC2004:LIC7280-PV    Autoclave 4 Compartment 6 Level (%)    Float\n",
    "PPO:PV2004:ZI7121    Autoclave 4 Train 1 Level Control Valve Open Position (%)    Float\n",
    "PPO:PV2005:ZI7131    Autoclave 4 Train 2 Level Control Valve Open Position (%)    Float\n",
    "PPO:PV2004:FIC7121-PV    Autoclave 4 Train 1 Level Control Quench Flow Volume (m3/h)    Float\n",
    "PPO:PV2005:FIC7131-PV    Autoclave 4 Train 2 Level Control Quench Flow Volume (m3/h)    Float\n",
    "PPO:L-AC4_S2_2HR_SQL    Autoclave 4 Discharge Sulphide Sulphur 3 Hourly Sample (Mass %)    Float\n",
    "PPO:L-ACD4_ORP_3HR_SQL    Autoclave 4 Discharge ORP 3 Hourly Sample (mV)    Float\n",
    "PPO:L-ACD4_H2SO4_3HR_SQL    Autoclave 4 Feed Sulphuric Acid 3 Hourly Sample (g/L)    Float'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnDescdict={}\n",
    "ColumnNumber=0\n",
    "ColumnNumdict={}\n",
    "ColumnDtypedict={}\n",
    "\n",
    "for i in translate.split(\"\\n\"):\n",
    "    if i.split(\" \")[0] == \"PPO:L-AC4\":\n",
    "        ColumnName=' '.join([str(elem) for elem in i.split(\" \")[0:2]])\n",
    "        ColumnDescdict[ColumnName] =' '.join([str(elem) for elem in i.split(\" \")[5:-4]]) \n",
    "        ColumnDtypedict[ColumnName]=i.split(\" \")[-1]\n",
    "        ColumnNumdict[ColumnName]=ColumnNumber\n",
    "    else:\n",
    "        ColumnName=i.split(\" \")[0]\n",
    "        ColumnDescdict[ColumnName] =' '.join([str(elem) for elem in i.split(\" \")[4:-4]]) \n",
    "        ColumnDtypedict[ColumnName]=i.split(\" \")[-1]\n",
    "        ColumnNumdict[ColumnName]=ColumnNumber\n",
    "    ColumnNumber+=1\n",
    "    \n",
    "for columnname in df_raw.columns:\n",
    "    if columnname not in ColumnDescdict.keys():\n",
    "        print(columnname)\n",
    "for key in ColumnDescdict.keys():\n",
    "    if key not in df_raw.columns:\n",
    "        print(key)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-0553ae7d244f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from tame_the_temp.src.process import load_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (1,2,3,4,5,6,7,8,63,64) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (35) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (64) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (63,64) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (35,63) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "df_raw=load_data(\"tame_the_temp/data/raw/train/20190601162260/\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the dictionary we created earlier is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    '''\n",
    "    A small function to display pandas DataFrames easier.\n",
    "    For a large dataframe use it thus: \n",
    "    >>> display_all(df.tail().T)\n",
    "    '''\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)\n",
    "\n",
    "def _extract_y_value(df):\n",
    "    \"\"\"The target or y-value here is the field PPO:AC4_1A:TIC7201-PV, lagged by one hour.\n",
    "    This should probably be left unchanged.\"\"\"\n",
    "    x_columns = df.columns.values.tolist()\n",
    "    df['target_timestamp'] = df['timestamp'] - pd.Timedelta(seconds=3600)\n",
    "    df['target_PPO:AC4_1A:TIC7201-PV'] = df['PPO:AC4_1A:TIC7201-PV']\n",
    "    x_df = df[x_columns]\n",
    "    y_df = df[['target_timestamp', 'target_PPO:AC4_1A:TIC7201-PV']]\n",
    "    merged_df = pd.merge(x_df, y_df, left_on='timestamp', right_on='target_timestamp')\n",
    "    x_df = merged_df[x_columns].drop(columns=['timestamp'])\n",
    "    y_df = merged_df[['target_PPO:AC4_1A:TIC7201-PV']].rename(columns={\n",
    "        'target_PPO:AC4_1A:TIC7201-PV': 'PPO:AC4_1A:TIC7201-PV'\n",
    "    })\n",
    "    return x_df, y_df\n",
    "\n",
    "def split_vals(a,n,b=0): return a[b:n].copy(), a[n:].copy()\n",
    "\n",
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the default workflow.\n",
    "df=df_raw\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "strings_to_replace = ['I/O Timeout', 'Bad Input', 'Over Range', 'Under Range', 'Arc Off-line']\n",
    "df = df.replace(strings_to_replace, np.nan)\n",
    "data_columns = list(df.columns)\n",
    "# drop rows containing null/nan values\n",
    "df = df[df[data_columns].notnull().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['target_timestamp', 'target_PPO:AC4_1A:TIC7201-PV'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d5cb091ab8e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_y_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mn_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12000\u001b[0m  \u001b[0;31m# same as Kaggle's test set size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_trn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b5bdf97bc314>\u001b[0m in \u001b[0;36m_extract_y_value\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target_PPO:AC4_1A:TIC7201-PV'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'target_timestamp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     y_df = merged_df[['target_PPO:AC4_1A:TIC7201-PV']].rename(columns={\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m'target_PPO:AC4_1A:TIC7201-PV'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'PPO:AC4_1A:TIC7201-PV'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['target_timestamp', 'target_PPO:AC4_1A:TIC7201-PV'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X, Y = _extract_y_value(df)\n",
    "n_valid = 12000  # same as Kaggle's test set size\n",
    "n_trn = len(df)-n_valid\n",
    "X_train, X_valid = split_vals(X, n_trn,-110000)\n",
    "y_train, y_valid = split_vals(Y, n_trn,-110000)\n",
    "# Convert column vectors from shape (N,1) to (N,).\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "# A bunch of entries in y_train contain floats as strings.\n",
    "for num,i in enumerate(y_train):\n",
    "    if type(i) != type(4.5):\n",
    "        y_train[num]=float(y_train[num])\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_train_row=0\n",
    "n_valid = 12000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0290761217852187, 3.6930767597514524, 0.9984297218450069, -1081.2526872292049]\n",
      "CPU times: user 18.2 s, sys: 1.87 s, total: 20.1 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is the default workflow.\n",
    "df=df_raw\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "strings_to_replace = ['I/O Timeout', 'Bad Input', 'Over Range', 'Under Range', 'Arc Off-line']\n",
    "df = df.replace(strings_to_replace, np.nan)\n",
    "data_columns = list(df.columns)\n",
    "# drop rows containing null/nan values\n",
    "df = df[df[data_columns].notnull().all(axis=1)].loc[start_train_row:,:]\n",
    "\n",
    "X, Y = _extract_y_value(df)\n",
    "n_trn = len(df)-n_valid\n",
    "X_train, X_valid = split_vals(X, n_trn)\n",
    "y_train, y_valid = split_vals(Y, n_trn)\n",
    "# Convert column vectors from shape (N,1) to (N,).\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "# A bunch of entries in y_train contain floats as strings.\n",
    "for num,i in enumerate(y_train):\n",
    "    if type(i) != type(4.5):\n",
    "        y_train[num]=float(y_train[num])\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "m = LinearRegression(n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:832: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2186512637582104, 0.42969558767139404, 0.9999817659184653, -13.651220085966001, 0.9986194359952285]\n",
      "CPU times: user 1min 49s, sys: 1.8 s, total: 1min 51s\n",
      "Wall time: 32.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is the default workflow.\n",
    "df=df_raw\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "strings_to_replace = ['I/O Timeout', 'Bad Input', 'Over Range', 'Under Range', 'Arc Off-line']\n",
    "df = df.replace(strings_to_replace, np.nan)\n",
    "data_columns = list(df.columns)\n",
    "# drop rows containing null/nan values\n",
    "df = df[df[data_columns].notnull().all(axis=1)].loc[start_train_row:,:]\n",
    "\n",
    "X, Y = _extract_y_value(df)\n",
    "n_trn = len(df)-n_valid\n",
    "X_train, X_valid = split_vals(X, n_trn)\n",
    "y_train, y_valid = split_vals(Y, n_trn)\n",
    "# Convert column vectors from shape (N,1) to (N,).\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "# A bunch of entries in y_train contain floats as strings.\n",
    "for num,i in enumerate(y_train):\n",
    "    if type(i) != type(4.5):\n",
    "        y_train[num]=float(y_train[num])\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "m = RandomForestRegressor(n_jobs=-1,n_estimators=20,min_samples_leaf=10,max_features=0.2,oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5580616668584244, 1.4885128983887839, 0.9990741317441217, -174.8155195970003]\n",
      "CPU times: user 8min 12s, sys: 1.82 s, total: 8min 14s\n",
      "Wall time: 8min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is the default workflow.\n",
    "df=df_raw\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "strings_to_replace = ['I/O Timeout', 'Bad Input', 'Over Range', 'Under Range', 'Arc Off-line']\n",
    "df = df.replace(strings_to_replace, np.nan)\n",
    "data_columns = list(df.columns)\n",
    "# drop rows containing null/nan values\n",
    "df = df[df[data_columns].notnull().all(axis=1)].loc[start_train_row:,:]\n",
    "\n",
    "X, Y = _extract_y_value(df)\n",
    "n_trn = len(df)-n_valid\n",
    "X_train, X_valid = split_vals(X, n_trn)\n",
    "y_train, y_valid = split_vals(Y, n_trn)\n",
    "# Convert column vectors from shape (N,1) to (N,).\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "# A bunch of entries in y_train contain floats as strings.\n",
    "for num,i in enumerate(y_train):\n",
    "    if type(i) != type(4.5):\n",
    "        y_train[num]=float(y_train[num])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "m = GradientBoostingRegressor(min_samples_split=2)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.9671179467147932, 14.24092506040198, 0.9939975281193651, -16091.681132453483]\n",
      "CPU times: user 9min 57s, sys: 12.2 s, total: 10min 9s\n",
      "Wall time: 10min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is the default workflow.\n",
    "df=df_raw\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "strings_to_replace = ['I/O Timeout', 'Bad Input', 'Over Range', 'Under Range', 'Arc Off-line']\n",
    "df = df.replace(strings_to_replace, np.nan)\n",
    "data_columns = list(df.columns)\n",
    "# drop rows containing null/nan values\n",
    "df = df[df[data_columns].notnull().all(axis=1)].loc[start_train_row:,:]\n",
    "\n",
    "X, Y = _extract_y_value(df)\n",
    "n_trn = len(df)-n_valid\n",
    "X_train, X_valid = split_vals(X, n_trn)\n",
    "y_train, y_valid = split_vals(Y, n_trn)\n",
    "# Convert column vectors from shape (N,1) to (N,).\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "# A bunch of entries in y_train contain floats as strings.\n",
    "for num,i in enumerate(y_train):\n",
    "    if type(i) != type(4.5):\n",
    "        y_train[num]=float(y_train[num])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "m = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram based Gradient Boosting (not implemented in this version of scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.experimental import enable_hist_gradient_boosting\n",
    "#from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "#\n",
    "#m = HistGradientBoostingClassifier()\n",
    "#m.fit(X_train, y_train)\n",
    "#print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LassoCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default score: 2.79920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.502477247640214, 2.854806018716902, 0.9953212423058407, -645.7034999111702]\n",
      "CPU times: user 51 s, sys: 2.15 s, total: 53.2 s\n",
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is the default workflow.\n",
    "df=df_raw\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "strings_to_replace = ['I/O Timeout', 'Bad Input', 'Over Range', 'Under Range', 'Arc Off-line']\n",
    "df = df.replace(strings_to_replace, np.nan)\n",
    "data_columns = list(df.columns)\n",
    "# drop rows containing null/nan values\n",
    "df = df[df[data_columns].notnull().all(axis=1)].loc[start_train_row:,:]\n",
    "\n",
    "X, Y = _extract_y_value(df)\n",
    "n_trn = len(df)-n_valid\n",
    "X_train, X_valid = split_vals(X, n_trn)\n",
    "y_train, y_valid = split_vals(Y, n_trn)\n",
    "# Convert column vectors from shape (N,1) to (N,).\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "# A bunch of entries in y_train contain floats as strings.\n",
    "for num,i in enumerate(y_train):\n",
    "    if type(i) != type(4.5):\n",
    "        y_train[num]=float(y_train[num])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "m = LassoCV()\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.029095868041736, 3.6903747085383447, 0.9984296912820666, -1079.6695994196925]\n",
      "CPU times: user 19.6 s, sys: 2 s, total: 21.6 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is the default workflow.\n",
    "df=df_raw\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "strings_to_replace = ['I/O Timeout', 'Bad Input', 'Over Range', 'Under Range', 'Arc Off-line']\n",
    "df = df.replace(strings_to_replace, np.nan)\n",
    "data_columns = list(df.columns)\n",
    "# drop rows containing null/nan values\n",
    "df = df[df[data_columns].notnull().all(axis=1)].loc[start_train_row:,:]\n",
    "\n",
    "X, Y = _extract_y_value(df)\n",
    "n_trn = len(df)-n_valid\n",
    "X_train, X_valid = split_vals(X, n_trn)\n",
    "y_train, y_valid = split_vals(Y, n_trn)\n",
    "# Convert column vectors from shape (N,1) to (N,).\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "# A bunch of entries in y_train contain floats as strings.\n",
    "for num,i in enumerate(y_train):\n",
    "    if type(i) != type(4.5):\n",
    "        y_train[num]=float(y_train[num])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "m = RidgeCV()\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "\n",
    "\n",
    "estimators = [('Random Forest', RandomForestRegressor(random_state=42)),\n",
    "              ('Lasso', LassoCV()),\n",
    "              ('Gradient Boosting', GradientBoostingRegressor(random_state=0))]\n",
    "\n",
    "stacking_regressor = StackingRegressor(estimators=estimators,\n",
    "                                       final_estimator=RidgeCV())\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "print_score(stacking_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop non-AC1 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3355282748498256, 0.30835887290565717, 0.9979195840841786, -6.54509831457756]\n"
     ]
    }
   ],
   "source": [
    "# List of relevant cols.\n",
    "firstACcols='''timestamp    datetime of record in yyyy-mm-dd hh:mm:ss format    datetime\n",
    "PPO:AC4_1A:TIC7201-PV    Autoclave 4 Compartment 1A Temperature (°C)    Float\n",
    "PPO:AC4_1A:FIC7201-PV    Autoclave 4 Compartment 1A O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_1A:FIC7271-PV    Autoclave 4 Compartment 1A Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_1A:WIC7211-PV    Autoclave 4 Compartment 1A Oxygen Mass Flow (t/h)    Float\n",
    "PPO:PU2033:FI7061    Autoclave 4 Feed Pump PU2033 Volume Flow (m3/h)    Float\n",
    "PPO:PU2034:FI7062    Autoclave 4 Feed Pump PU2034 Volume Flow (m3/h)    Float\n",
    "PPO:PU2035:FI7063    Autoclave 4 Feed Pump PU2035 Volume Flow (m3/h)    Float\n",
    "PPO:PU2033:WI7061    Autoclave 4 Feed Pump PU2033 Mass Flow (t/h)    Float\n",
    "PPO:PU2034:WI7062    Autoclave 4 Feed Pump PU2034 Mass Flow (t/h)    Float\n",
    "PPO:PU2035:WI7063    Autoclave 4 Feed Pump PU2035 Mass Flow (t/h)    Float\n",
    "PPO:PU2033:WIC7064-PV    Autoclave 4 Total Mass Flow (t/h)    Float\n",
    "PPO:PU2741:TIC7182-PV    Autoclave 4 Feed Slurry Temperature (°C)    Float\n",
    "PPO:L-AC4 FD_S2_2HR_SQL    Autoclave 4 Feed Sulphide Sulphur 3 Hourly Sample (Mass %)    Float\n",
    "PPO:L-AC4FD_RS_2HR_SQL    Autoclave 4 Feed Reactive Sulphur 3 Hourly Sample (Mass %)    Float\n",
    "PPO:L-AC4 FD_CACO3_2HR_SQL    Autoclave 4 Feed Calcium Carbonate 3 Hourly Sample (Mass %)    Float\n",
    "PPO:L-AC4 FD_PH_2HR_SQL    Autoclave 4 Feed pH 3 Hourly Sample (pH)    Float\n",
    "PPO:AG2241:JIC7201-PV    Autoclave 4 Compartment 1A Agitator Power (kWhr)    Float\n",
    "PPO:AG2241:AG2241-RPM    Autoclave 4 Compartment 1A Agitator Speed (rpm)    Float\n",
    "PPO:AC2004:PIC7065A-PV    Autoclave 4 Pressure (kPa)    Float\n",
    "PPO:PV2016:PV7127    Autoclave 4 Train 1 Pressure Control Valve Open Position (%)    Float\n",
    "PPO:PV2017:PV7137    Autoclave 4 Train 2 Pressure Control Valve Open Position (%)    Float\n",
    "PPO:AC2004:LIC7280-PV    Autoclave 4 Compartment 6 Level (%)    Float\n",
    "PPO:PV2004:ZI7121    Autoclave 4 Train 1 Level Control Valve Open Position (%)    Float\n",
    "PPO:PV2005:ZI7131    Autoclave 4 Train 2 Level Control Valve Open Position (%)    Float\n",
    "PPO:PV2004:FIC7121-PV    Autoclave 4 Train 1 Level Control Quench Flow Volume (m3/h)    Float\n",
    "PPO:PV2005:FIC7131-PV    Autoclave 4 Train 2 Level Control Quench Flow Volume (m3/h)    Float\n",
    "PPO:L-AC4_S2_2HR_SQL    Autoclave 4 Discharge Sulphide Sulphur 3 Hourly Sample (Mass %)    Float\n",
    "PPO:L-ACD4_ORP_3HR_SQL    Autoclave 4 Discharge ORP 3 Hourly Sample (mV)    Float\n",
    "PPO:L-ACD4_H2SO4_3HR_SQL    Autoclave 4 Feed Sulphuric Acid 3 Hourly Sample (g/L)    Float'''\n",
    "\n",
    "\n",
    "# Convert above string into series of dicts.\n",
    "ColumnDescdict={}\n",
    "ColumnNumber=0\n",
    "ColumnNumdict={}\n",
    "ColumnDtypedict={}\n",
    "\n",
    "for i in firstACcols.split(\"\\n\"):\n",
    "    if i.split(\" \")[0] == \"PPO:L-AC4\":\n",
    "        ColumnName=' '.join([str(elem) for elem in i.split(\" \")[0:2]])\n",
    "        ColumnDescdict[ColumnName] =' '.join([str(elem) for elem in i.split(\" \")[5:-4]]) \n",
    "        ColumnDtypedict[ColumnName]=i.split(\" \")[-1]\n",
    "        ColumnNumdict[ColumnName]=ColumnNumber\n",
    "    else:\n",
    "        ColumnName=i.split(\" \")[0]\n",
    "        ColumnDescdict[ColumnName] =' '.join([str(elem) for elem in i.split(\" \")[4:-4]]) \n",
    "        ColumnDtypedict[ColumnName]=i.split(\" \")[-1]\n",
    "        ColumnNumdict[ColumnName]=ColumnNumber\n",
    "    ColumnNumber+=1\n",
    "\n",
    "# build list of cols to keep.\n",
    "firstACcolsList=[]\n",
    "for col in ColumnNumdict:\n",
    "    firstACcolsList.append(col)\n",
    "\n",
    "# this is the default workflow.\n",
    "df=df_raw\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "strings_to_replace = ['I/O Timeout', 'Bad Input', 'Over Range', 'Under Range', 'Arc Off-line']\n",
    "df = df.replace(strings_to_replace, np.nan)\n",
    "data_columns = list(df.columns)\n",
    "# drop rows containing null/nan values\n",
    "df = df[df[data_columns].notnull().all(axis=1)].loc[start_train_row:,:]\n",
    "\n",
    "# Drop non-AC1 columns\n",
    "for col in df.columns:\n",
    "    if col not in firstACcolsList:\n",
    "        df.drop(col,axis=1,inplace=True)\n",
    "        \n",
    "X, Y = _extract_y_value(df)\n",
    "n_trn = len(df)-n_valid\n",
    "X_train, X_valid = split_vals(X, n_trn)\n",
    "y_train, y_valid = split_vals(Y, n_trn)\n",
    "# Convert column vectors from shape (N,1) to (N,).\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "# A bunch of entries in y_train contain floats as strings.\n",
    "for num,i in enumerate(y_train):\n",
    "    if type(i) != type(4.5):\n",
    "        y_train[num]=float(y_train[num])\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "m = LinearRegression(n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['timestamp', 'PPO:AC4_1A:TIC7201-PV', 'PPO:AC4_1A:FIC7201-PV', 'PPO:AC4_1A:FIC7271-PV', 'PPO:AC4_1A:WIC7211-PV', 'PPO:PU2033:FI7061', 'PPO:PU2034:FI7062', 'PPO:PU2035:FI7063', 'PPO:PU2033:WI7061', 'PPO:PU2034:WI7062', 'PPO:PU2035:WI7063', 'PPO:PU2033:WIC7064-PV', 'PPO:PU2741:TIC7182-PV', 'PPO:L-AC4 FD_S2_2HR_SQL', 'PPO:L-AC4FD_RS_2HR_SQL', 'PPO:L-AC4 FD_CACO3_2HR_SQL', 'PPO:L-AC4 FD_PH_2HR_SQL', 'PPO:AG2241:JIC7201-PV', 'PPO:AG2241:AG2241-RPM', 'PPO:AC2004:PIC7065A-PV', 'PPO:PV2016:PV7127', 'PPO:PV2017:PV7137', 'PPO:AC2004:LIC7280-PV', 'PPO:PV2004:ZI7121', 'PPO:PV2005:ZI7131', 'PPO:PV2004:FIC7121-PV', 'PPO:PV2005:FIC7131-PV', 'PPO:L-AC4_S2_2HR_SQL', 'PPO:L-ACD4_ORP_3HR_SQL', 'PPO:L-ACD4_H2SO4_3HR_SQL']\n"
     ]
    }
   ],
   "source": [
    "print(firstACcolsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:832: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24318155770941885, 4.851874369939238, 0.9999537877132745, 0.9951532973730806, 0.9967172722133794]\n",
      "Features sorted by their score:\n",
      "[(0.2869, 'PPO:AC4_1C:FIC7273-PV'), (0.1868, 'PPO:AC4_2:FIC7274-PV'), (0.1455, 'PPO:AC4_1A:FIC7271-PV'), (0.0936, 'PPO:AC4_4:FIC7276-PV'), (0.0597, 'PPO:AC4_3:FIC7275-PV'), (0.0561, 'PPO:AC4_1B:FIC7272-PV'), (0.0538, 'PPO:AC4_6:FIC7278-PV'), (0.051, 'PPO:AC4_5:FIC7277-PV'), (0.0367, 'PPO:AG2245:AG2245-RPM'), (0.0148, 'timestamp'), (0.0021, 'PPO:AC2004:LIC7280-PV'), (0.0011, 'PPO:AC4_1C:TIC7203-PV'), (0.001, 'PPO:AG2244:AG2244-RPM'), (0.001, 'PPO:AG2241:AG2241-RPM'), (0.0007, 'PPO:PU2033:FI7061'), (0.0007, 'PPO:AC4_1C:FIC7203-PV'), (0.0006, 'PPO:PV2004:FIC7121-PV'), (0.0004, 'PPO:PV2005:ZI7131'), (0.0004, 'PPO:PU2033:WI7061'), (0.0004, 'PPO:AC4_1B:WIC7212-PV'), (0.0004, 'PPO:AC4_1B:TIC7202-PV'), (0.0003, 'PPO:PU2741:TIC7182-PV'), (0.0003, 'PPO:PU2035:WI7063'), (0.0003, 'PPO:PU2034:WI7062'), (0.0003, 'PPO:L-AC4 FD_CACO3_2HR_SQL'), (0.0003, 'PPO:AC4_5:WIC7217-PV'), (0.0003, 'PPO:AC4_1B:FIC7202-PV'), (0.0002, 'PPO:PV2016:PV7127'), (0.0002, 'PPO:PV2005:FIC7131-PV'), (0.0002, 'PPO:PU2034:FI7062'), (0.0002, 'PPO:PU2033:WIC7064-PV'), (0.0002, 'PPO:L-ACD4_H2SO4_3HR_SQL'), (0.0002, 'PPO:AC4_6:TIC7208-PV'), (0.0002, 'PPO:AC4_4:WIC7216-PV'), (0.0002, 'PPO:AC4_3:WIC7215-PV'), (0.0002, 'PPO:AC4_3:TIC7205-PV'), (0.0002, 'PPO:AC4_2:TIC7204-PV'), (0.0002, 'PPO:AC4_1C:WIC7213-PV'), (0.0002, 'PPO:AC4_1A:WIC7211-PV'), (0.0002, 'PPO:AC4_1A:TIC7201-PV'), (0.0002, 'PPO:AC4_1A:FIC7201-PV'), (0.0002, 'PPO:AC2004:PIC7065A-PV'), (0.0001, 'PPO:PV2004:ZI7121'), (0.0001, 'PPO:PU2035:FI7063'), (0.0001, 'PPO:L-ACD4_ORP_3HR_SQL'), (0.0001, 'PPO:L-AC4_S2_2HR_SQL'), (0.0001, 'PPO:L-AC4FD_RS_2HR_SQL'), (0.0001, 'PPO:L-AC4 FD_S2_2HR_SQL'), (0.0001, 'PPO:L-AC4 FD_PH_2HR_SQL'), (0.0001, 'PPO:AG2248_PWR'), (0.0001, 'PPO:AG2243:JIC7203-PV'), (0.0001, 'PPO:AC4_6:FIC7208-PV'), (0.0001, 'PPO:AC4_5:FIC7207-PV'), (0.0001, 'PPO:AC4_4:TIC7206-PV'), (0.0001, 'PPO:AC4_4:FIC7206-PV'), (0.0001, 'PPO:AC4_3:FIC7205-PV'), (0.0001, 'PPO:AC4_2:WIC7214-PV'), (0.0001, 'PPO:AC4_2:FIC7204-PV'), (0.0001, 'PPO:AC2004:AVEG-TEMP'), (0.0, 'PPO:AG2247_PWR'), (0.0, 'PPO:AG2246_PWR'), (0.0, 'PPO:AG2245:JIC7205-PV'), (0.0, 'PPO:AG2244:JIC7204-PV'), (0.0, 'PPO:AG2243:AG2243-RPM'), (0.0, 'PPO:AG2242:JIC7202-PV'), (0.0, 'PPO:AG2242:AG2242-RPM'), (0.0, 'PPO:AG2241:JIC7201-PV'), (0.0, 'PPO:AC4_6:WIC7218-PV'), (0.0, 'PPO:AC4_5:TIC7207-PV')]\n"
     ]
    }
   ],
   "source": [
    "# this is the default workflow.\n",
    "df=df_raw\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "strings_to_replace = ['I/O Timeout', 'Bad Input', 'Over Range', 'Under Range', 'Arc Off-line']\n",
    "df = df.replace(strings_to_replace, np.nan)\n",
    "data_columns = list(df.columns)\n",
    "# drop rows containing null/nan values\n",
    "df = df[df[data_columns].notnull().all(axis=1)].loc[start_train_row:,:]\n",
    "\n",
    "X, Y = _extract_y_value(df)\n",
    "n_trn = len(df)-n_valid\n",
    "X_train, X_valid = split_vals(X, n_trn)\n",
    "y_train, y_valid = split_vals(Y, n_trn)\n",
    "# Convert column vectors from shape (N,1) to (N,).\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "# A bunch of entries in y_train contain floats as strings.\n",
    "for num,i in enumerate(y_train):\n",
    "    if type(i) != type(4.5):\n",
    "        y_train[num]=float(y_train[num])\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "names=df.columns\n",
    "m = RandomForestRegressor(n_jobs=-1,n_estimators=20,min_samples_leaf=10,max_features=0.2,oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)\n",
    "\n",
    "print (\"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), m.feature_importances_), names), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "featimport=sorted(zip(map(lambda x: round(x, 4), m.feature_importances_), names), \n",
    "             reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880472, 72)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880472, 16)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the default workflow.\n",
    "df=df_raw\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "strings_to_replace = ['I/O Timeout', 'Bad Input', 'Over Range', 'Under Range', 'Arc Off-line']\n",
    "df = df.replace(strings_to_replace, np.nan)\n",
    "data_columns = list(df.columns)\n",
    "# drop rows containing null/nan values\n",
    "df = df[df[data_columns].notnull().all(axis=1)].loc[start_train_row:,:]\n",
    "\n",
    "for importance, feature in featimport:\n",
    "    if feature not in ['PPO:AC4_1A:TIC7201-PV','datetime']:\n",
    "        if importance < 0.001:\n",
    "            df.drop(columns=feature, axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'PPO:AC2004:LIC7280-PV', 'PPO:AC4_1A:FIC7271-PV',\n",
       "       'PPO:AC4_1A:TIC7201-PV', 'PPO:AC4_1B:FIC7272-PV',\n",
       "       'PPO:AC4_1C:FIC7273-PV', 'PPO:AC4_1C:TIC7203-PV',\n",
       "       'PPO:AC4_2:FIC7274-PV', 'PPO:AC4_3:FIC7275-PV', 'PPO:AC4_4:FIC7276-PV',\n",
       "       'PPO:AC4_5:FIC7277-PV', 'PPO:AC4_6:FIC7278-PV', 'PPO:AG2241:AG2241-RPM',\n",
       "       'PPO:AG2244:AG2244-RPM', 'PPO:AG2245:AG2245-RPM', 'PPO:PV2017:PV7137'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:832: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5212409062116475, 17.253380268179857, 0.9997876886706715, 0.9387119690584856, 0.9967574967699321]\n"
     ]
    }
   ],
   "source": [
    "X, Y = _extract_y_value(df)\n",
    "n_trn = len(df)-n_valid\n",
    "X_train, X_valid = split_vals(X, n_trn)\n",
    "y_train, y_valid = split_vals(Y, n_trn)\n",
    "# Convert column vectors from shape (N,1) to (N,).\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "# A bunch of entries in y_train contain floats as strings.\n",
    "for num,i in enumerate(y_train):\n",
    "    if type(i) != type(4.5):\n",
    "        y_train[num]=float(y_train[num])\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "names=df.columns\n",
    "m = RandomForestRegressor(n_jobs=-1,n_estimators=20,min_samples_leaf=10,max_features=0.2,oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1314649 , 0.00514289, 0.35344147, 0.00219668, 0.00483383,\n",
       "       0.27503726, 0.0265351 , 0.0284996 , 0.08536632, 0.00167334,\n",
       "       0.0096786 , 0.00689235, 0.0025445 , 0.01288615, 0.05380702])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
