{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate='''timestamp    datetime of record in yyyy-mm-dd hh:mm:ss format    datetime\n",
    "PPO:AC4_1A:TIC7201-PV    Autoclave 4 Compartment 1A Temperature (°C)    Float\n",
    "PPO:AC4_1B:TIC7202-PV    Autoclave 4 Compartment 1B Temperature (°C)    Float\n",
    "PPO:AC4_1C:TIC7203-PV    Autoclave 4 Compartment 1C Temperature (°C)    Float\n",
    "PPO:AC4_2:TIC7204-PV    Autoclave 4 Compartment 2 Temperature (°C)    Float\n",
    "PPO:AC4_3:TIC7205-PV    Autoclave 4 Compartment 3 Temperature (°C)    Float\n",
    "PPO:AC4_4:TIC7206-PV    Autoclave 4 Compartment 4 Temperature (°C)    Float\n",
    "PPO:AC4_5:TIC7207-PV    Autoclave 4 Compartment 5 Temperature (°C)    Float\n",
    "PPO:AC4_6:TIC7208-PV    Autoclave 4 Compartment 6 Temperature (°C)    Float\n",
    "PPO:AC2004:AVEG-TEMP    Autoclave 4 Average of Selected Temperature (°C)    Float\n",
    "PPO:AC4_1A:FIC7201-PV    Autoclave 4 Compartment 1A O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_1A:FIC7271-PV    Autoclave 4 Compartment 1A Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_1B:FIC7202-PV    Autoclave 4 Compartment 1B O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_1B:FIC7272-PV    Autoclave 4 Compartment 1B Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_1C:FIC7203-PV    Autoclave 4 Compartment 1C O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_1C:FIC7273-PV    Autoclave 4 Compartment 1C Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_2:FIC7204-PV    Autoclave 4 Compartment 2 O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_2:FIC7274-PV    Autoclave 4 Compartment 2 Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_3:FIC7205-PV    Autoclave 4 Compartment 3 O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_3:FIC7275-PV    Autoclave 4 Compartment 3 Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_4:FIC7206-PV    Autoclave 4 Compartment 4 O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_4:FIC7276-PV    Autoclave 4 Compartment 4 Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_5:FIC7207-PV    Autoclave 4 Compartment 5 O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_5:FIC7277-PV    Autoclave 4 Compartment 5 Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_6:FIC7208-PV    Autoclave 4 Compartment 6 O2 Quench Water (m3/h)    Float\n",
    "PPO:AC4_6:FIC7278-PV    Autoclave 4 Compartment 6 Steam Quench Water (m3/h)    Float\n",
    "PPO:AC4_1A:WIC7211-PV    Autoclave 4 Compartment 1A Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_1B:WIC7212-PV    Autoclave 4 Compartment 1B Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_1C:WIC7213-PV    Autoclave 4 Compartment 1C Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_2:WIC7214-PV    Autoclave 4 Compartment 2 Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_3:WIC7215-PV    Autoclave 4 Compartment 3 Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_4:WIC7216-PV    Autoclave 4 Compartment 4 Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_5:WIC7217-PV    Autoclave 4 Compartment 5 Oxygen Mass Flow (t/h)    Float\n",
    "PPO:AC4_6:WIC7218-PV    Autoclave 4 Compartment 6 Oxygen Mass Flow (t/h)    Float\n",
    "PPO:PU2033:FI7061    Autoclave 4 Feed Pump PU2033 Volume Flow (m3/h)    Float\n",
    "PPO:PU2034:FI7062    Autoclave 4 Feed Pump PU2034 Volume Flow (m3/h)    Float\n",
    "PPO:PU2035:FI7063    Autoclave 4 Feed Pump PU2035 Volume Flow (m3/h)    Float\n",
    "PPO:PU2033:WI7061    Autoclave 4 Feed Pump PU2033 Mass Flow (t/h)    Float\n",
    "PPO:PU2034:WI7062    Autoclave 4 Feed Pump PU2034 Mass Flow (t/h)    Float\n",
    "PPO:PU2035:WI7063    Autoclave 4 Feed Pump PU2035 Mass Flow (t/h)    Float\n",
    "PPO:PU2033:WIC7064-PV    Autoclave 4 Total Mass Flow (t/h)    Float\n",
    "PPO:PU2741:TIC7182-PV    Autoclave 4 Feed Slurry Temperature (°C)    Float\n",
    "PPO:L-AC4 FD_S2_2HR_SQL    Autoclave 4 Feed Sulphide Sulphur 3 Hourly Sample (Mass %)    Float\n",
    "PPO:L-AC4FD_RS_2HR_SQL    Autoclave 4 Feed Reactive Sulphur 3 Hourly Sample (Mass %)    Float\n",
    "PPO:L-AC4 FD_CACO3_2HR_SQL    Autoclave 4 Feed Calcium Carbonate 3 Hourly Sample (Mass %)    Float\n",
    "PPO:L-AC4 FD_PH_2HR_SQL    Autoclave 4 Feed pH 3 Hourly Sample (pH)    Float\n",
    "PPO:AG2241:JIC7201-PV    Autoclave 4 Compartment 1A Agitator Power (kWhr)    Float\n",
    "PPO:AG2242:JIC7202-PV    Autoclave 4 Compartment 1B Agitator Power (kWhr)    Float\n",
    "PPO:AG2243:JIC7203-PV    Autoclave 4 Compartment 1C Agitator Power (kWhr)    Float\n",
    "PPO:AG2244:JIC7204-PV    Autoclave 4 Compartment 2 Agitator Power (kWhr)    Float\n",
    "PPO:AG2245:JIC7205-PV    Autoclave 4 Compartment 3 Agitator Power (kWhr)    Float\n",
    "PPO:AG2246_PWR    Autoclave 4 Compartment 4 Agitator Power (kWhr)    Float\n",
    "PPO:AG2247_PWR    Autoclave 4 Compartment 5 Agitator Power (kWhr)    Float\n",
    "PPO:AG2248_PWR    Autoclave 4 Compartment 6 Agitator Power (kWhr)    Float\n",
    "PPO:AG2241:AG2241-RPM    Autoclave 4 Compartment 1A Agitator Speed (rpm)    Float\n",
    "PPO:AG2242:AG2242-RPM    Autoclave 4 Compartment 1B Agitator Speed (rpm)    Float\n",
    "PPO:AG2243:AG2243-RPM    Autoclave 4 Compartment 1C Agitator Speed (rpm)    Float\n",
    "PPO:AG2244:AG2244-RPM    Autoclave 4 Compartment 2 Agitator Speed (rpm)    Float\n",
    "PPO:AG2245:AG2245-RPM    Autoclave 4 Compartment 3 Agitator Speed (rpm)    Float\n",
    "PPO:AC2004:PIC7065A-PV    Autoclave 4 Pressure (kPa)    Float\n",
    "PPO:PV2016:PV7127    Autoclave 4 Train 1 Pressure Control Valve Open Position (%)    Float\n",
    "PPO:PV2017:PV7137    Autoclave 4 Train 2 Pressure Control Valve Open Position (%)    Float\n",
    "PPO:AC2004:LIC7280-PV    Autoclave 4 Compartment 6 Level (%)    Float\n",
    "PPO:PV2004:ZI7121    Autoclave 4 Train 1 Level Control Valve Open Position (%)    Float\n",
    "PPO:PV2005:ZI7131    Autoclave 4 Train 2 Level Control Valve Open Position (%)    Float\n",
    "PPO:PV2004:FIC7121-PV    Autoclave 4 Train 1 Level Control Quench Flow Volume (m3/h)    Float\n",
    "PPO:PV2005:FIC7131-PV    Autoclave 4 Train 2 Level Control Quench Flow Volume (m3/h)    Float\n",
    "PPO:L-AC4_S2_2HR_SQL    Autoclave 4 Discharge Sulphide Sulphur 3 Hourly Sample (Mass %)    Float\n",
    "PPO:L-ACD4_ORP_3HR_SQL    Autoclave 4 Discharge ORP 3 Hourly Sample (mV)    Float\n",
    "PPO:L-ACD4_H2SO4_3HR_SQL    Autoclave 4 Feed Sulphuric Acid 3 Hourly Sample (g/L)    Float'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnDescdict={}\n",
    "ColumnNumber=0\n",
    "ColumnNumdict={}\n",
    "ColumnDtypedict={}\n",
    "\n",
    "for i in translate.split(\"\\n\"):\n",
    "    if i.split(\" \")[0] == \"PPO:L-AC4\":\n",
    "        ColumnName=' '.join([str(elem) for elem in i.split(\" \")[0:2]])\n",
    "        ColumnDescdict[ColumnName] =' '.join([str(elem) for elem in i.split(\" \")[5:-4]]) \n",
    "        ColumnDtypedict[ColumnName]=i.split(\" \")[-1]\n",
    "        ColumnNumdict[ColumnName]=ColumnNumber\n",
    "    else:\n",
    "        ColumnName=i.split(\" \")[0]\n",
    "        ColumnDescdict[ColumnName] =' '.join([str(elem) for elem in i.split(\" \")[4:-4]]) \n",
    "        ColumnDtypedict[ColumnName]=i.split(\" \")[-1]\n",
    "        ColumnNumdict[ColumnName]=ColumnNumber\n",
    "    ColumnNumber+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tame_the_temp.src.process import load_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (1,2,3,4,5,6,7,8,63,64) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (35) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (64) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (63,64) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/home/cdinneen/miniconda3/envs/TtT-FAI7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (35,63) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "df_raw=load_data(\"tame_the_temp/data/raw/train/20190601162260/\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the dictionary we created earlier is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columnname in df_raw.columns:\n",
    "    if columnname not in ColumnDescdict.keys():\n",
    "        print(columnname)\n",
    "for key in ColumnDescdict.keys():\n",
    "    if key not in df_raw.columns:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    '''\n",
    "    A small function to display pandas DataFrames easier.\n",
    "    For a large dataframe use it thus: \n",
    "    >>> display_all(df.tail().T)\n",
    "    '''\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_y_value(df):\n",
    "    \"\"\"The target or y-value here is the field PPO:AC4_1A:TIC7201-PV, lagged by one hour.\n",
    "    This should probably be left unchanged.\"\"\"\n",
    "    x_columns = df.columns.values.tolist()\n",
    "    df['target_timestamp'] = df['timestamp'] - pd.Timedelta(seconds=3600)\n",
    "    df['target_PPO:AC4_1A:TIC7201-PV'] = df['PPO:AC4_1A:TIC7201-PV']\n",
    "    x_df = df[x_columns]\n",
    "    y_df = df[['target_timestamp', 'target_PPO:AC4_1A:TIC7201-PV']]\n",
    "    merged_df = pd.merge(x_df, y_df, left_on='timestamp', right_on='target_timestamp')\n",
    "    x_df = merged_df[x_columns].drop(columns=['timestamp'])\n",
    "    y_df = merged_df[['target_PPO:AC4_1A:TIC7201-PV']].rename(columns={\n",
    "        'target_PPO:AC4_1A:TIC7201-PV': 'PPO:AC4_1A:TIC7201-PV'\n",
    "    })\n",
    "    return x_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the default workflow.\n",
    "df=df_raw\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "strings_to_replace = ['I/O Timeout', 'Bad Input', 'Over Range', 'Under Range', 'Arc Off-line']\n",
    "df = df.replace(strings_to_replace, np.nan)\n",
    "data_columns = list(df.columns)\n",
    "# drop rows containing null/nan values\n",
    "df = df[df[data_columns].notnull().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display_all(df.tail().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display_all(df.describe(include='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = _extract_y_value(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all(X.tail().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all(Y.tail().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vals(a,n,b=0): return a[b:n].copy(), a[n:].copy()\n",
    "\n",
    "n_valid = 12000  # same as Kaggle's test set size\n",
    "n_trn = len(df)-n_valid\n",
    "X_train, X_valid = split_vals(X, n_trn,-110000)\n",
    "y_train, y_valid = split_vals(Y, n_trn,-110000)\n",
    "# Convert column vectors from shape (N,1) to (N,).\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "# A bunch of entries in y_train contain floats as strings.\n",
    "for num,i in enumerate(y_train):\n",
    "    if type(i) != type(4.5):\n",
    "        y_train[num]=float(y_train[num])\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_est in [10, 20, 40, 60, 80, 100]:\n",
    "    m = RandomForestRegressor(n_jobs=-1,n_estimators=n_est,oob_score=True)\n",
    "    m.fit(X_train, y_train)\n",
    "    print(n_est)\n",
    "    print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for samp_leaf in [1,3,5,10,25]:\n",
    "    m = RandomForestRegressor(n_jobs=-1,n_estimators=80,min_samples_leaf=samp_leaf,oob_score=True)\n",
    "    %time m.fit(X_train, y_train)\n",
    "    print(samp_leaf)\n",
    "    print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nest     maxfeat       score\n",
    "# 40        auto         10.74\n",
    "# 40        0.8          13.01\n",
    "#160        0.2          11.93\n",
    "#160        sqrt         13.55\n",
    "#160        log2         15.44\n",
    "\n",
    "for max_feat  in [0.2, 'sqrt', 'log2']:#, 0.5, 0.8, 'auto']:\n",
    "    m = RandomForestRegressor(n_jobs=-1,n_estimators=160,min_samples_leaf=3,max_features=max_feat,oob_score=True)\n",
    "    %time m.fit(X_train, y_train)\n",
    "    print(max_feat)\n",
    "    print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_est in [10, 20, 40, 60, 100, 150, 200 ]:\n",
    "    m = RandomForestRegressor(n_jobs=-1,n_estimators=n_est,min_samples_leaf=10,max_features=0.2,oob_score=True)\n",
    "    m.fit(X_train, y_train)\n",
    "    print(n_est)\n",
    "    print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_est in [10, 20, 40, 60, 100, 150, 200 ]:\n",
    "    m = RandomForestRegressor(n_jobs=-1,n_estimators=40,min_samples_leaf=3,max_features='auto',oob_score=True)\n",
    "    m.fit(X_train, y_train)\n",
    "    print(n_est)\n",
    "    print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3,4,5,6,7,8,9,0]:\n",
    "    m = RandomForestRegressor(n_jobs=-1,n_estimators=20,min_samples_leaf=10,max_features=0.2,oob_score=True)\n",
    "    m.fit(X_train, y_train)\n",
    "    print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to add additional features. TO do this we want to add measurements from the past to the present row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ts_col(df, shift):\n",
    "    '''\n",
    "    pd.DataFrame(nxm), str, int -> pd.DataFrame(n,m+1)\n",
    "    \n",
    "    Add a shift to all columns in the df of shift x 30 seconds, then append it to df.\n",
    "    '''\n",
    "    # deep copy the df, excluding any previously shifted columns.\n",
    "    shifted_df=df[[col for col in df.columns.values if col[-4:] != 'step']].copy()\n",
    "    # drop the target column.\n",
    "    shifted_df=shifted_df.drop(columns=['PPO:AC4_1A:TIC7201-PV'])\n",
    "    #shift by shift lots of 30 seconds\n",
    "    shifted_df['target_timestamp'] = shifted_df['timestamp'] + pd.Timedelta(seconds=shift*30)\n",
    "    shifted_df.drop(columns=['timestamp'])\n",
    "    suffix='_+'+str(shift)+'step'\n",
    "    merged_df = pd.merge(df, shifted_df, left_on='timestamp', right_on='target_timestamp',suffixes=('',suffix))\n",
    "    return merged_df.drop(columns=['timestamp'+suffix, 'target_timestamp'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lags=add_ts_col(df,2)\n",
    "df_lags=add_ts_col(df_lags,4)\n",
    "df_lags=add_ts_col(df_lags,10)\n",
    "df_lags=add_ts_col(df_lags,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, Y = _extract_y_value(df_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((103972, 341), (103972,), (6028, 341), (6028,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_vals(a,n,b=0): return a[b:n].copy(), a[n:].copy()\n",
    "\n",
    "n_valid = 12000  # same as Kaggle's test set size\n",
    "n_trn = len(df)-n_valid\n",
    "X_train, X_valid = split_vals(X, n_trn,-110000)\n",
    "y_train, y_valid = split_vals(Y, n_trn,-110000)\n",
    "# Convert column vectors from shape (N,1) to (N,).\n",
    "y_train=y_train.values.ravel()\n",
    "y_valid=y_valid.values.ravel()\n",
    "# A bunch of entries in y_train contain floats as strings.\n",
    "for num,i in enumerate(y_train):\n",
    "    if type(i) != type(4.5):\n",
    "        y_train[num]=float(y_train[num])\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09105687908504885, 16.78365704759653, 0.9999982530265725, 0.9484329333682762, 0.9999917869326936]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1,n_estimators=40,min_samples_leaf=3,max_features='auto',oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col='PPO:AC2004:AVEG-TEMP_+1step'\n",
    "col[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_raw.columns.values[2:]:\n",
    "    print(col)\n",
    "    df_raw=add_ts_col(df_raw,col,2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
